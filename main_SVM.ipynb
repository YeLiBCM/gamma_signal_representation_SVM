{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use SVM to investigate which gamma frequency band represents the contrast level of grating stimuli.\n",
    "\n",
    "Check the following link for the research story of why I am doing it: https://www.cell.com/current-biology/fulltext/S0960-9822(19)31020-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0960982219310206%3Fshowall%3Dtrue#secsectitle0035\n",
    "\n",
    "The following analysis is relevant to the result session __\"Gratings Contrast Can Be Decoded Better Using NBG Than BBG\"__, and method session __\"Visual grating contrast classification\"__.\n",
    "\n",
    "Two frequency band of interest: \n",
    "<br>\n",
    "1) 20-60 Hz (variable name in the code is 'NBG');\n",
    "<br>\n",
    "2) 70-150 Hz (variable name in the code is 'BBG').\n",
    "\n",
    "This notebook will: \n",
    "<br>\n",
    "1) read event files to extract contrast information of trials from the task.\n",
    "<br>\n",
    "2) read feature file to extract feature matrix as the input for the SVM modeling.\n",
    "<br>\n",
    "3) apply SVM modeling with data of some example data\n",
    "<br>\n",
    "4) show the code to loop through the pipeline with all the data contained in this project.\n",
    "\n",
    "Note: \n",
    "<br>\n",
    "This notebook won't provide the codes for the preprocessing step for the ECoG data. The data is already clean and transform into time-frequency data using Morlet wavelet transform (codes were not provided in the repository either). You can take a loot at 'extract_epoch.m' (use in MATLAB) to see how I extract the task epoch into the feature file I need for the modeling. However, you may have a different way to structure your EEG/ECoG file and may do it in a different way.\n",
    "\n",
    "This notebook mainly demonstrate how the modeling is done in one single electrode in one patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn import svm,preprocessing\n",
    "from sklearn.model_selection import LeaveOneOut, permutation_test_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1-3 will demonstrate the pipeline with data from one single example electrode\n",
    "\n",
    "## 1. Read event file to extract the condition labels of task trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path of the file and read the mat file of condition events. I have provided one example event file from one task block of one patient subject in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path and read event file\n",
    "# modify the event_path based on how you save your data\n",
    "\n",
    "event_path   = 'example_data/task_events_example.mat'\n",
    "event_file   = sio.loadmat(event_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, there are trials of a given condition that I want to exclude, here I delete the events of those trials (trials present patients with a grating stimulus at the orientation of 45 degree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get contrast labels and detele those at 45 degree\n",
    "contrast     = np.asscalar(event_file['events_info']['trial_contrast'])\n",
    "odd_orient   = np.asscalar(event_file['events_info']['trial_orientation']) \n",
    "contrast_new = np.delete(contrast, np.where(odd_orient == 45)[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I recode the task condition into 1,2,3 for three different task conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the task conditions (1 = 20% contrast, 2 = 50% contrast, 3 = 100% contrast)\n",
    "label_v                 = np.reshape(contrast_new,(90,))\n",
    "label_v[label_v == 1]   = 3\n",
    "label_v[label_v == 0.5] = 2\n",
    "label_v[label_v == 0.2] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label_v is the label file (output/ observed values) we need for the SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read the time-series data\n",
    "With this notebook, the real data of one electrode from our patients is provided in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read time series data\n",
    "# the data with be the spectrogram data of one task block\n",
    "tf_path = 'example_data/tf_epochs_example.mat'\n",
    "tf_data = sio.loadmat(tf_path) # it is a dict file, the \"tf_epochs\" in it is the features we need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the shape of the data to understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 250, 90)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data['tf_epochs'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions of tf_data['tf_epochs'] mean:\n",
    "<br>\n",
    "\"200\" frequency points, from 2 Hz to 201 Hz;\n",
    "<br>\n",
    "\"250\" time poins, from 250 ms to 500 ms after the stimulus onset;\n",
    "<br>\n",
    "\"90\" trials of the task -- grating stimuli at three contrast levels were shown to the subject for 90 times in one task.\n",
    "\n",
    "Take the average of the data across the time window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_avg = np.mean(tf_data['tf_epochs'],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the variable of the boundary of two gamma frequency bands and extract the feature input matrixs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two gammas\n",
    "NBG = [20,60]\n",
    "BBG = [70,150]\n",
    "\n",
    "# get feature inputs\n",
    "feature_NBG = tf_avg[(NBG[0]-2):(NBG[1]-1),:].T # transform the matrix to make the column is frequency info\n",
    "feature_BBG = tf_avg[(BBG[0]-2):(BBG[1]-1),:].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and test the SVM model.\n",
    "\n",
    "The model pipeline will:\n",
    "<br>\n",
    "1) Scale the data using MinMax method.\n",
    "<br>\n",
    "2) Implement a leave-one-out-cross-validation method to get the prediction accuracy.\n",
    "<br>\n",
    "3) Get the significant level of the prediction accuracy using permutation test. (In this notebook we will use 1000-time-permutation).\n",
    "\n",
    "In the brain science, the aim is not to create a fancy model to have the highest prediction performance, but to use modeling method to compare the prediction performance of different brain signals or a given signal from different brain areas.\n",
    "\n",
    "We want to compare:\n",
    "<br>\n",
    "1) The prediction performance of model using NBG as input vs using BBG as input -- so we can see which frequency band is representing the stimulus contrast information.\n",
    "<br>\n",
    "2) The prediction performance of model using NBG within visual cortex vs outside of visual cortex -- it serves as a great control analysis to validate the SVM model. The NBG from areas outside of visual cortex should not be able to predict the stimulus visual properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of the SVM modeling\n",
    "def linear_SVM(feature_mx,npermu,label):\n",
    "    \"\"\"This function conduct SVM on single electrode data.\n",
    "    \n",
    "    feature_mx: the feature input of the model.\n",
    "    \n",
    "    nperm: number of permutation times. \n",
    "    \n",
    "    label: label vector. \"\"\"\n",
    " \n",
    "    # SVM pipeline\n",
    "    loo = LeaveOneOut()\n",
    "    pipe = Pipeline([('scaler', preprocessing.MinMaxScaler()),('clf', svm.SVC(kernel='linear'))])\n",
    "    score, permutation_scores, pvalue = permutation_test_score(pipe, feature_mx, label, scoring = 'accuracy', cv=loo, n_permutations=npermu, n_jobs = -1)\n",
    "\n",
    "    return score,pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of model prediction using NBG is:0.6444444444444445; p-value: 0.000999000999000999\n",
      "the accuracy of model prediction using BBG is:0.4222222222222222; p-value: 0.060939060939060936\n"
     ]
    }
   ],
   "source": [
    "# get the prediction results\n",
    "score_NBG, pvalue_NBG = linear_SVM(feature_NBG,1000,label_v)\n",
    "score_BBG, pvalue_BBG = linear_SVM(feature_BBG,1000,label_v)\n",
    "print('the accuracy of model prediction using NBG is:' + str(score_NBG) + '; p-value: ' + str(pvalue_NBG))\n",
    "print('the accuracy of model prediction using BBG is:' + str(score_BBG) + '; p-value: ' + str(pvalue_BBG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this example electrode we can see the NBG is representing the stimulus visual property -- contrast level. \n",
    "\n",
    "Next I will extract the data of an electrode from areas outside of visual cortex and do the same modeling again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and make input feature\n",
    "tf_path = 'example_data/tf_epochs_example_nonvisual.mat'\n",
    "tf_data = sio.loadmat(tf_path)\n",
    "tf_avg = np.mean(tf_data['tf_epochs'],axis =1)\n",
    "feature_nonvisual = tf_avg[(NBG[0]-2):(NBG[1]-1),:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of model prediction using NBG outside of visual area is:0.36666666666666664; p-value: 0.17682317682317683\n"
     ]
    }
   ],
   "source": [
    "# get the prediction result\n",
    "score_nonvisual, pvalue_nonvisual = linear_SVM(feature_nonvisual,1000,label_v)\n",
    "print('the accuracy of model prediction using NBG outside of visual area is:' + str(score_nonvisual) + '; p-value: ' + str(pvalue_nonvisual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the NBG outside of visual area cannot predict the contrast level of the visual stimulus well, so we know the model works.\n",
    "Next, loop through all the visual electrodes from all the patients to get the prediction accuracy and p-value for each electrode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loop through data from all electrodes to the SVM pipeline\n",
    "Due to the big size of our raw data, I can't provide all the data we used for this project in the repository. However, I will demonstrate the way I save the subject information in the dataframe and the code to loop through the data using the dataframe.\n",
    "\n",
    "Let me first make a \"fake\" subject information sheet first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datafram that saves the subject information\n",
    "d = {'subject_code': ['AAA','AAB','AAC','AAD'],\n",
    "     'task_block_code': ['001,013','009','014,023','005,006'],\n",
    "     'electrode_code': ['097,098,099,100,122,123','065,066,077,088,089','001,002,003','123,124,125,126,127']}\n",
    "df = pd.DataFrame(data = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_code</th>\n",
       "      <th>task_block_code</th>\n",
       "      <th>electrode_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>001,013</td>\n",
       "      <td>097,098,099,100,122,123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAB</td>\n",
       "      <td>009</td>\n",
       "      <td>065,066,077,088,089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAC</td>\n",
       "      <td>014,023</td>\n",
       "      <td>001,002,003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAD</td>\n",
       "      <td>005,006</td>\n",
       "      <td>123,124,125,126,127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_code task_block_code           electrode_code\n",
       "0          AAA         001,013  097,098,099,100,122,123\n",
       "1          AAB             009      065,066,077,088,089\n",
       "2          AAC         014,023              001,002,003\n",
       "3          AAD         005,006      123,124,125,126,127"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my real project, I have more subjects, more task blocks and more electrodes. In addition, I separate the electrodes into \"visual\" and \"non_visual\", here I just made the dataframe simple enough to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to save the result\n",
    "# I need to record: subject code, electrode_code, accuracy, p-value\n",
    "# Note: for a given electrode, data from multiple task blocks will be concatenate together for SVM modeling\n",
    "df_result = pd.DataFrame(columns=['subject','elec','NBG_acc','NBG_p','BBG_acc','BBG_p'])\n",
    "\n",
    "# save it into csv\n",
    "df_result.to_csv('result.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>elec</th>\n",
       "      <th>NBG_acc</th>\n",
       "      <th>NBG_p</th>\n",
       "      <th>BBG_acc</th>\n",
       "      <th>BBG_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subject, elec, NBG_acc, NBG_p, BBG_acc, BBG_p]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concate_blks(block_string,sbj,ci):\n",
    "    '''\n",
    "    concate the time-frequency data from different task blocks together\n",
    "    \n",
    "    block_string: element value in column task_block_code in subject information dataframe\n",
    "    sbj: element value in column subject_code in subject information dataframe\n",
    "    ci: electrode code of a single electrode, such as the '097' of subject AAA in the example dataframe\n",
    "    \n",
    "    return: numpy array of time-frequency data concatenated across blocks for one electrode\n",
    "    '''\n",
    "    \n",
    "    blocks = block_string.split()\n",
    "    \n",
    "    for i in range(len(blocks)):\n",
    "        block_code = blocks[i]\n",
    "        \n",
    "        # set path (it is a fake path here, modify it for your own project)\n",
    "        path = '/{}/{}/{}.mat'.format(sbj,block_code,ci)\n",
    "        tf_data = sio.loadmat(tf_path)\n",
    "        \n",
    "        if i == 0:\n",
    "            concated_tf_data = tf_data['tf_epochs']\n",
    "        else:\n",
    "            to_concate = tf_data['tf_epochs']\n",
    "            concated_tf_data = np.concatenate((concated_tf_data,to_concate), axis = 2)\n",
    "            \n",
    "    return concated_tf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_mx(tf_data,freq_band):\n",
    "    '''\n",
    "    get the feature input to be used in the SVM\n",
    "    \n",
    "    tf_data: time-frequency data\n",
    "    freq_band: frequency boundary of the signal of interest\n",
    "\n",
    "    return: numpy array of feature matrix (row: samples/task trials; col: frequency point)\n",
    "    '''\n",
    "    \n",
    "    tf_avg = np.mean(tf_data,axis =1)\n",
    "    feature_mx = tf_avg[(freq_band[0]-2):(freq_band[1]-1),:].T\n",
    "    \n",
    "    return feature_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(sbj_code,block):\n",
    "    '''\n",
    "    return the label of one block of task from a given subject\n",
    "    '''\n",
    "    # set path (it is a fake path)\n",
    "    event_path   = '/{}/{}.mat'.format(sbj_code,block)\n",
    "    event_file   = sio.loadmat(event_path)\n",
    "    \n",
    "    contrast     = np.asscalar(event_file['events_info']['trial_contrast'])\n",
    "    odd_orient   = np.asscalar(event_file['events_info']['trial_orientation']) \n",
    "    contrast_new = np.delete(contrast, np.where(odd_orient == 45)[0])\n",
    "\n",
    "    label_v                 = np.reshape(contrast_new,(90,))\n",
    "    label_v[label_v == 1]   = 3\n",
    "    label_v[label_v == 0.5] = 2\n",
    "    label_v[label_v == 0.2] = 1\n",
    "    \n",
    "    return label_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A trick:__\n",
    "<br>\n",
    "At this point, you might use the above functions to write some code using parallel processing if you have a large size of data (usually in fMRI studies). However, in ECoG studies, we are not able to have many subjects for one project, so I won't use parallel processing. <br> I will have a function to apply SVM modeling and save the result for each subject, so if I want to be cautious I can do the modeling for each subject one-by-one and check the result after each of them is done. I will still provide another block of code to loop through all the subjects in the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbj_SVM(sbj_code,npermu = 1000):\n",
    "    '''\n",
    "    run the pipeline of SVM for electrodes of one subject\n",
    "    \n",
    "    npermu : times of permutation test\n",
    "    '''\n",
    "    \n",
    "    # read the csv file to save the result\n",
    "    df_result = pd.read_csv('result.scv') # change the path as needed\n",
    "    \n",
    "    # get the row of data for the given subject\n",
    "    row_sbj = df.loc[df['subject_code']=='AAA'] \n",
    "    \n",
    "    # get block info and electrode list\n",
    "    block_str = row_sbj['task_block_code'].values\n",
    "    electrode_list = row_sbj['electrode_code'].values\n",
    "    \n",
    "    # extract the label\n",
    "    blocks = block_str[0].split(',')\n",
    "    \n",
    "    for iblk in range(len(blocks)):\n",
    "        label_v_blk = extract_label(sbj_code,blocks[iblk])\n",
    "        if iblk == 0:\n",
    "            label_v = label_v_blk\n",
    "        else:\n",
    "            label_v = np.concatenate((label_v,label_v_blk))\n",
    "    \n",
    "    # loop through the electrode\n",
    "    electrode_list = electrode_list[0].split(',')\n",
    "    \n",
    "    for ielec in range(len(electrode_list)):\n",
    "        ci = electrode_list[ielec]\n",
    "        \n",
    "        # concatenate data\n",
    "        tf_data = concate_blks(block_str,sbj_code,ci)\n",
    "        \n",
    "        # get the feature matrix\n",
    "        feature_NBG = (tf_data,[20,60])\n",
    "        feature_BBG = (tf_data,[70,150])\n",
    "        \n",
    "        # run SVM\n",
    "        score_NBG, p_NBG = linear_SVM(feature_NBG,npermu,label_v)\n",
    "        score_BBG, p_BBG = linear_SVM(feature_BBG,npermu,label_v)\n",
    "        \n",
    "        # append the data to the result dataframe\n",
    "        data_to_add = pd.DataFrame([[sbj_code,ci,score_NBG,p_NBG,score_BBG,p_BBG]],columns = df_result.columns)\n",
    "        df_result = df_result.append(data_to_add, ignore_index = True)\n",
    "    \n",
    "    # save the result\n",
    "    df_result.to_csv('result.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the following code to loop through all the subjects \n",
    "\n",
    "nsbj = len(df['subject_code'])\n",
    "\n",
    "for isbj in range(nsbj):\n",
    "    sbj_code = df['subject_code'][isbj]\n",
    "    sbj_SVM(sbj_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
